{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dce9044",
   "metadata": {},
   "source": [
    "# MRI Anomaly Detection and Data Interpretation System\n",
    "\n",
    "This notebook implements an AI-powered system for MRI anomaly detection using LangChain, OpenAI GPT-4o-mini, and Tavily AI API with interactive image upload capabilities.\n",
    "\n",
    "## Features\n",
    "- 🖼️ Interactive MRI image upload with drag-and-drop support\n",
    "- 🧠 AI-powered anomaly detection simulation\n",
    "- 📚 Medical context search using Tavily AI\n",
    "- 💬 Detailed explanations using OpenAI GPT-4o-mini via LangChain\n",
    "- 📄 Professional HTML report generation\n",
    "- 🔄 Batch processing capabilities\n",
    "- 📊 Comprehensive error handling and logging\n",
    "\n",
    "## Important Medical Disclaimer\n",
    "⚠️ **This system is for demonstration and educational purposes only. It should not be used for actual medical diagnosis. Always consult qualified healthcare professionals for medical advice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a30fdd",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install all the required packages for our MRI analysis system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5626be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai langchain-community openai requests pillow numpy matplotlib python-dotenv ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50128543",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries including LangChain components, OpenAI, image processing libraries, and Jupyter widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "import base64\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import io\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Jupyter widgets for file upload\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d264ef",
   "metadata": {},
   "source": [
    "## 3. Environment Configuration\n",
    "\n",
    "Set up API keys and environment variables securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "TAVILY_API_KEY = \"your-tavily-api-key-here\"\n",
    "\n",
    "print(\"✅ API keys configured successfully!\")\n",
    "print(\"🔐 Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e5eac2",
   "metadata": {},
   "source": [
    "## 4. MRI Image Handler Class\n",
    "\n",
    "Handle MRI image validation, preprocessing, and display functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIImageHandler:\n",
    "    \"\"\"Handles MRI image upload, validation, and preprocessing\"\"\"\n",
    "    \n",
    "    SUPPORTED_FORMATS = ['jpg', 'jpeg', 'png', 'dicom', 'dcm']\n",
    "    MAX_SIZE_MB = 10\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_image(image_path: str = None, image_data: bytes = None) -> bool:\n",
    "        \"\"\"Validate image format and size\"\"\"\n",
    "        if image_path:\n",
    "            if not os.path.exists(image_path):\n",
    "                raise ValueError(f\"Image path does not exist: {image_path}\")\n",
    "            \n",
    "            # Check file format\n",
    "            file_ext = image_path.split('.')[-1].lower()\n",
    "            if file_ext not in MRIImageHandler.SUPPORTED_FORMATS:\n",
    "                raise ValueError(f\"Invalid format. Supported: {', '.join(MRIImageHandler.SUPPORTED_FORMATS)}\")\n",
    "            \n",
    "            # Check file size\n",
    "            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)\n",
    "            if file_size_mb > MRIImageHandler.MAX_SIZE_MB:\n",
    "                raise ValueError(f\"File too large. Maximum size: {MRIImageHandler.MAX_SIZE_MB}MB\")\n",
    "        \n",
    "        elif image_data:\n",
    "            # Check data size\n",
    "            data_size_mb = len(image_data) / (1024 * 1024)\n",
    "            if data_size_mb > MRIImageHandler.MAX_SIZE_MB:\n",
    "                raise ValueError(f\"File too large. Maximum size: {MRIImageHandler.MAX_SIZE_MB}MB\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_image_base64(image_path: str = None, image_data: bytes = None) -> str:\n",
    "        \"\"\"Encode image to base64 for API transmission\"\"\"\n",
    "        if image_path:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        elif image_data:\n",
    "            return base64.b64encode(image_data).decode('utf-8')\n",
    "        else:\n",
    "            raise ValueError(\"Either image_path or image_data must be provided\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def display_image(image_path: str = None, image_data: bytes = None, title: str = \"MRI Scan\"):\n",
    "        \"\"\"Display the MRI image\"\"\"\n",
    "        if image_path:\n",
    "            img = Image.open(image_path)\n",
    "        elif image_data:\n",
    "            img = Image.open(io.BytesIO(image_data))\n",
    "        else:\n",
    "            raise ValueError(\"Either image_path or image_data must be provided\")\n",
    "            \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img, cmap='gray' if img.mode == 'L' else None)\n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_uploaded_image(image_data: bytes, filename: str) -> str:\n",
    "        \"\"\"Save uploaded image data to file\"\"\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        return filename\n",
    "\n",
    "print(\"✅ MRI Image Handler class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f22c2",
   "metadata": {},
   "source": [
    "## 5. Tavily AI Integration Class\n",
    "\n",
    "Create integration with Tavily AI API for medical context search and MRI analysis simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TavilyMRIAnalyzer:\n",
    "    \"\"\"Handles MRI analysis using Tavily AI API\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.tavily.com/v1\"\n",
    "        \n",
    "    def analyze_mri(self, image_path: str = None, image_data: bytes = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze MRI image for anomalies\n",
    "        Note: Since Tavily is a search API, we'll simulate MRI analysis\n",
    "        \"\"\"\n",
    "        # Validate image\n",
    "        if image_path:\n",
    "            MRIImageHandler.validate_image(image_path=image_path)\n",
    "        elif image_data:\n",
    "            MRIImageHandler.validate_image(image_data=image_data)\n",
    "        \n",
    "        # Simulated analysis results based on random patterns\n",
    "        import random\n",
    "        \n",
    "        # Generate realistic simulated abnormalities\n",
    "        possible_abnormalities = [\n",
    "            {\n",
    "                \"type\": \"lesion\",\n",
    "                \"location\": \"left frontal lobe\",\n",
    "                \"size\": \"12mm x 8mm\",\n",
    "                \"confidence\": round(random.uniform(0.75, 0.95), 2),\n",
    "                \"characteristics\": \"hyperintense on T2-weighted images\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"white matter changes\",\n",
    "                \"location\": \"periventricular region\",\n",
    "                \"severity\": \"mild\",\n",
    "                \"confidence\": round(random.uniform(0.80, 0.98), 2),\n",
    "                \"characteristics\": \"scattered punctate foci\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"microhemorrhage\",\n",
    "                \"location\": \"right parietal lobe\",\n",
    "                \"size\": \"3mm\",\n",
    "                \"confidence\": round(random.uniform(0.70, 0.90), 2),\n",
    "                \"characteristics\": \"hypointense on T2* sequences\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"cortical atrophy\",\n",
    "                \"location\": \"bilateral temporal lobes\",\n",
    "                \"severity\": \"moderate\",\n",
    "                \"confidence\": round(random.uniform(0.85, 0.95), 2),\n",
    "                \"characteristics\": \"widened sulci and reduced cortical thickness\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Randomly select 1-3 abnormalities for simulation\n",
    "        num_abnormalities = random.randint(1, 3)\n",
    "        selected_abnormalities = random.sample(possible_abnormalities, num_abnormalities)\n",
    "        \n",
    "        simulated_results = {\n",
    "            \"status\": \"success\",\n",
    "            \"image_id\": f\"mri_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            \"abnormalities\": selected_abnormalities,\n",
    "            \"overall_assessment\": \"Abnormalities detected requiring clinical correlation\" if selected_abnormalities else \"No significant abnormalities detected\"\n",
    "        }\n",
    "        \n",
    "        return simulated_results\n",
    "    \n",
    "    def search_medical_context(self, abnormality_type: str) -> List[str]:\n",
    "        \"\"\"Use Tavily to search for medical context about detected abnormalities\"\"\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"api_key\": self.api_key,\n",
    "            \"query\": f\"MRI {abnormality_type} clinical significance treatment options medical imaging\",\n",
    "            \"search_depth\": \"advanced\",\n",
    "            \"max_results\": 3\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/search\",\n",
    "                json=payload,\n",
    "                headers=headers\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                return [result.get('content', '') for result in results.get('results', [])]\n",
    "            else:\n",
    "                print(f\"Tavily search error: {response.status_code}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching medical context: {e}\")\n",
    "            return []\n",
    "\n",
    "print(\"✅ Tavily MRI Analyzer class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028b3b3",
   "metadata": {},
   "source": [
    "## 6. OpenAI GPT-4 Integration with LangChain\n",
    "\n",
    "Implement LangChain chains using OpenAI GPT-4o-mini for generating medical explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalExplanationGenerator:\n",
    "    \"\"\"Generates medical explanations using OpenAI GPT-4o-mini via LangChain\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.3,  # Lower temperature for more consistent medical explanations\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "    def create_explanation_chain(self):\n",
    "        \"\"\"Create a LangChain chain for generating medical explanations\"\"\"\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an experienced radiologist providing clear, professional explanations of MRI findings.\n",
    "\n",
    "MRI Analysis Results:\n",
    "{abnormalities}\n",
    "\n",
    "Additional Medical Context:\n",
    "{medical_context}\n",
    "\n",
    "Please provide:\n",
    "1. A clear explanation of each detected abnormality\n",
    "2. The clinical significance of these findings\n",
    "3. Potential risks or concerns\n",
    "4. Recommended follow-up actions\n",
    "5. Important notes for the patient\n",
    "\n",
    "Format your response with clear sections and use both medical terminology (with explanations) \n",
    "and patient-friendly language. Be thorough but accessible.\n",
    "\n",
    "Remember: This is an AI-generated analysis and should be reviewed by a qualified medical professional.\n",
    "        \"\"\")\n",
    "        \n",
    "        # Use the new RunnableSequence syntax instead of deprecated LLMChain\n",
    "        chain = prompt_template | self.llm\n",
    "        \n",
    "        return chain\n",
    "    \n",
    "    def generate_explanation(self, abnormalities: List[Dict], medical_context: List[str]) -> str:\n",
    "        \"\"\"Generate comprehensive explanation of MRI findings\"\"\"\n",
    "        \n",
    "        # Format abnormalities for the prompt\n",
    "        abnormalities_text = self._format_abnormalities(abnormalities)\n",
    "        context_text = \"\\n\".join(medical_context) if medical_context else \"No additional context available\"\n",
    "        \n",
    "        # Run the chain using the new invoke method\n",
    "        chain = self.create_explanation_chain()\n",
    "        result = chain.invoke({\n",
    "            \"abnormalities\": abnormalities_text,\n",
    "            \"medical_context\": context_text\n",
    "        })\n",
    "        \n",
    "        # Extract content from the result\n",
    "        explanation = result.content if hasattr(result, 'content') else str(result)\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def _format_abnormalities(self, abnormalities: List[Dict]) -> str:\n",
    "        \"\"\"Format abnormalities data for the prompt\"\"\"\n",
    "        if not abnormalities:\n",
    "            return \"No abnormalities detected in this MRI scan.\"\n",
    "            \n",
    "        formatted = []\n",
    "        for i, abnormality in enumerate(abnormalities, 1):\n",
    "            formatted.append(f\"\"\"\n",
    "Abnormality {i}:\n",
    "- Type: {abnormality.get('type', 'Unknown')}\n",
    "- Location: {abnormality.get('location', 'Not specified')}\n",
    "- Size/Severity: {abnormality.get('size', abnormality.get('severity', 'Not specified'))}\n",
    "- Confidence: {abnormality.get('confidence', 0):.0%}\n",
    "- Characteristics: {abnormality.get('characteristics', 'Not specified')}\n",
    "            \"\"\".strip())\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "print(\"✅ Medical Explanation Generator class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa889f32",
   "metadata": {},
   "source": [
    "## 7. Report Generation System\n",
    "\n",
    "Generate professional HTML reports with comprehensive medical documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIReportGenerator:\n",
    "    \"\"\"Generates comprehensive MRI analysis reports\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_html_report(\n",
    "        image_filename: str,\n",
    "        analysis_results: Dict,\n",
    "        explanation: str,\n",
    "        patient_id: str = \"Anonymous\"\n",
    "    ) -> str:\n",
    "        \"\"\"Generate an HTML report with findings\"\"\"\n",
    "        \n",
    "        report_date = datetime.now().strftime(\"%B %d, %Y at %I:%M %p\")\n",
    "        \n",
    "        html_template = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>MRI Analysis Report</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            max-width: 900px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            line-height: 1.6;\n",
    "            background-color: #f8f9fa;\n",
    "        }}\n",
    "        .container {{\n",
    "            background-color: white;\n",
    "            padding: 30px;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "        .header {{\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 25px;\n",
    "            border-radius: 10px;\n",
    "            margin-bottom: 25px;\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .header h1 {{\n",
    "            margin: 0;\n",
    "            font-size: 2.2em;\n",
    "        }}\n",
    "        .section {{\n",
    "            margin-bottom: 30px;\n",
    "            padding: 20px;\n",
    "            background-color: #f8f9fa;\n",
    "            border-radius: 8px;\n",
    "            border-left: 5px solid #007bff;\n",
    "        }}\n",
    "        .abnormality {{\n",
    "            background-color: #fff3cd;\n",
    "            padding: 18px;\n",
    "            margin: 15px 0;\n",
    "            border-radius: 8px;\n",
    "            border-left: 5px solid #ffc107;\n",
    "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "        .explanation {{\n",
    "            background-color: #e8f4f8;\n",
    "            padding: 25px;\n",
    "            border-radius: 8px;\n",
    "            margin-top: 20px;\n",
    "            border-left: 5px solid #17a2b8;\n",
    "        }}\n",
    "        .disclaimer {{\n",
    "            background-color: #f8d7da;\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            border-left: 5px solid #dc3545;\n",
    "            color: #721c24;\n",
    "        }}\n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 15px;\n",
    "            background-color: white;\n",
    "            border-radius: 8px;\n",
    "            overflow: hidden;\n",
    "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "        th, td {{\n",
    "            text-align: left;\n",
    "            padding: 12px 15px;\n",
    "            border-bottom: 1px solid #e9ecef;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #495057;\n",
    "            color: white;\n",
    "            font-weight: 600;\n",
    "        }}\n",
    "        .confidence-high {{ color: #28a745; font-weight: bold; }}\n",
    "        .confidence-medium {{ color: #ffc107; font-weight: bold; }}\n",
    "        .confidence-low {{ color: #dc3545; font-weight: bold; }}\n",
    "        .summary-stats {{\n",
    "            display: flex;\n",
    "            justify-content: space-around;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
    "            min-width: 120px;\n",
    "        }}\n",
    "        .stat-number {{\n",
    "            font-size: 2em;\n",
    "            font-weight: bold;\n",
    "            color: #007bff;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>🧠 MRI Analysis Report</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; font-size: 1.1em;\">AI-Powered Medical Image Analysis</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📋 Report Information</h2>\n",
    "            <table>\n",
    "                <tr><td><strong>Patient ID:</strong></td><td>{patient_id}</td></tr>\n",
    "                <tr><td><strong>Report Date:</strong></td><td>{report_date}</td></tr>\n",
    "                <tr><td><strong>Image File:</strong></td><td>{image_filename}</td></tr>\n",
    "                <tr><td><strong>Analysis ID:</strong></td><td>{analysis_results.get('image_id', 'N/A')}</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📊 Analysis Summary</h2>\n",
    "            <div class=\"summary-stats\">\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-number\">{len(analysis_results.get('abnormalities', []))}</div>\n",
    "                    <div>Abnormalities</div>\n",
    "                </div>\n",
    "                <div class=\"stat-card\">\n",
    "                    <div class=\"stat-number\">{analysis_results.get('status', 'Unknown').title()}</div>\n",
    "                    <div>Status</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <p><strong>Overall Assessment:</strong> {analysis_results.get('overall_assessment', 'Analysis complete')}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>🔍 Detected Abnormalities</h2>\n",
    "            {MRIReportGenerator._format_abnormalities_html(analysis_results.get('abnormalities', []))}\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>💡 Detailed Medical Interpretation</h2>\n",
    "            <div class=\"explanation\">\n",
    "                {explanation.replace(chr(10), '<br>')}\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section disclaimer\">\n",
    "            <h2>⚠️ Important Medical Disclaimer</h2>\n",
    "            <p style=\"font-weight: bold; margin-bottom: 15px;\">\n",
    "                This report is generated by an AI system for demonstration and educational purposes only.\n",
    "            </p>\n",
    "            <ul>\n",
    "                <li>This analysis should <strong>NEVER</strong> be used for actual medical diagnosis</li>\n",
    "                <li>Always consult qualified healthcare professionals for medical advice</li>\n",
    "                <li>This system is not a substitute for professional medical evaluation</li>\n",
    "                <li>Any medical decisions should be made only by licensed physicians</li>\n",
    "                <li>The AI may produce inaccurate or incomplete results</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: center; margin-top: 30px; color: #6c757d;\">\n",
    "            <p><small>Generated by MRI Anomaly Detection System | AI-Powered Medical Analysis Tool</small></p>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html_template\n",
    "    \n",
    "    @staticmethod\n",
    "    def _format_abnormalities_html(abnormalities: List[Dict]) -> str:\n",
    "        \"\"\"Format abnormalities as HTML\"\"\"\n",
    "        if not abnormalities:\n",
    "            return \"<div class='abnormality'><h3>✅ No Abnormalities Detected</h3><p>The AI analysis did not detect any significant abnormalities in this MRI scan.</p></div>\"\n",
    "        \n",
    "        html_parts = []\n",
    "        for i, abnormality in enumerate(abnormalities, 1):\n",
    "            confidence = abnormality.get('confidence', 0)\n",
    "            confidence_class = 'confidence-high' if confidence >= 0.8 else 'confidence-medium' if confidence >= 0.6 else 'confidence-low'\n",
    "            \n",
    "            html_parts.append(f\"\"\"\n",
    "            <div class=\"abnormality\">\n",
    "                <h3>🔸 Abnormality {i}: {abnormality.get('type', 'Unknown').title()}</h3>\n",
    "                <table>\n",
    "                    <tr><td><strong>📍 Location:</strong></td><td>{abnormality.get('location', 'Not specified')}</td></tr>\n",
    "                    <tr><td><strong>📏 Size/Severity:</strong></td><td>{abnormality.get('size', abnormality.get('severity', 'Not specified'))}</td></tr>\n",
    "                    <tr><td><strong>🎯 Confidence:</strong></td><td><span class=\"{confidence_class}\">{abnormality.get('confidence', 0):.0%}</span></td></tr>\n",
    "                    <tr><td><strong>🔬 Characteristics:</strong></td><td>{abnormality.get('characteristics', 'Not specified')}</td></tr>\n",
    "                </table>\n",
    "            </div>\n",
    "            \"\"\")\n",
    "        \n",
    "        return \"\".join(html_parts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_report(html_content: str, output_path: str = \"mri_report.html\"):\n",
    "        \"\"\"Save the HTML report to a file\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        return output_path\n",
    "\n",
    "print(\"✅ MRI Report Generator class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65fa9a",
   "metadata": {},
   "source": [
    "## 8. Main System Integration Class\n",
    "\n",
    "Create the main orchestrating class that combines all components into a complete MRI analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f01d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIAnalysisSystem:\n",
    "    \"\"\"Main system integrating all components\"\"\"\n",
    "    \n",
    "    def __init__(self, tavily_api_key: str):\n",
    "        self.image_handler = MRIImageHandler()\n",
    "        self.tavily_analyzer = TavilyMRIAnalyzer(tavily_api_key)\n",
    "        self.explanation_generator = MedicalExplanationGenerator()\n",
    "        self.report_generator = MRIReportGenerator()\n",
    "        \n",
    "        # Setup logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler('mri_analysis.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger('MRIAnalysisSystem')\n",
    "    \n",
    "    def analyze_mri_image(self, image_path: str = None, image_data: bytes = None, \n",
    "                         patient_id: str = \"Anonymous\", filename: str = \"uploaded_image.jpg\") -> Dict:\n",
    "        \"\"\"\n",
    "        Complete MRI analysis pipeline\n",
    "        \"\"\"\n",
    "        print(\"🔍 Starting MRI Analysis Pipeline...\")\n",
    "        self.logger.info(f\"Starting analysis for patient: {patient_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Validate and display image\n",
    "            print(\"\\n📸 Validating image...\")\n",
    "            if image_path:\n",
    "                self.image_handler.validate_image(image_path=image_path)\n",
    "                self.image_handler.display_image(image_path=image_path, title=\"📋 Original MRI Scan\")\n",
    "                image_filename = os.path.basename(image_path)\n",
    "            elif image_data:\n",
    "                self.image_handler.validate_image(image_data=image_data)\n",
    "                self.image_handler.display_image(image_data=image_data, title=\"📋 Uploaded MRI Scan\")\n",
    "                image_filename = filename\n",
    "            else:\n",
    "                raise ValueError(\"Either image_path or image_data must be provided\")\n",
    "            \n",
    "            # Step 2: Analyze MRI with Tavily (simulated)\n",
    "            print(\"\\n🧠 Analyzing MRI for anomalies...\")\n",
    "            analysis_results = self.tavily_analyzer.analyze_mri(image_path=image_path, image_data=image_data)\n",
    "            num_abnormalities = len(analysis_results.get('abnormalities', []))\n",
    "            print(f\"✓ Analysis complete: Found {num_abnormalities} potential abnormalit{'ies' if num_abnormalities != 1 else 'y'}\")\n",
    "            \n",
    "            # Step 3: Get medical context for each abnormality type\n",
    "            print(\"\\n📚 Gathering medical context from research...\")\n",
    "            medical_contexts = []\n",
    "            for abnormality in analysis_results.get('abnormalities', []):\n",
    "                print(f\"  🔍 Researching: {abnormality['type']}\")\n",
    "                context = self.tavily_analyzer.search_medical_context(abnormality['type'])\n",
    "                medical_contexts.extend(context)\n",
    "            \n",
    "            # Step 4: Generate detailed explanation\n",
    "            print(\"\\n💬 Generating medical explanation with AI...\")\n",
    "            explanation = self.explanation_generator.generate_explanation(\n",
    "                analysis_results.get('abnormalities', []),\n",
    "                medical_contexts\n",
    "            )\n",
    "            \n",
    "            # Step 5: Generate report\n",
    "            print(\"\\n📄 Creating comprehensive report...\")\n",
    "            html_report = self.report_generator.generate_html_report(\n",
    "                image_filename,\n",
    "                analysis_results,\n",
    "                explanation,\n",
    "                patient_id\n",
    "            )\n",
    "            \n",
    "            # Save report\n",
    "            report_filename = f\"mri_report_{patient_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "            report_path = self.report_generator.save_report(html_report, report_filename)\n",
    "            \n",
    "            # Log success\n",
    "            self.logger.info(f\"Analysis completed successfully. Report: {report_path}\")\n",
    "            \n",
    "            # Return results\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"analysis_results\": analysis_results,\n",
    "                \"explanation\": explanation,\n",
    "                \"report_path\": report_path,\n",
    "                \"html_report\": html_report\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error during analysis: {str(e)}\"\n",
    "            print(f\"\\n❌ {error_msg}\")\n",
    "            self.logger.error(error_msg, exc_info=True)\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def display_results_summary(self, results: Dict):\n",
    "        \"\"\"Display a summary of the analysis results\"\"\"\n",
    "        if results['success']:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✅ MRI ANALYSIS COMPLETE\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            analysis = results['analysis_results']\n",
    "            abnormalities = analysis.get('abnormalities', [])\n",
    "            \n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   • Abnormalities found: {len(abnormalities)}\")\n",
    "            print(f\"   • Report saved to: {results['report_path']}\")\n",
    "            print(f\"   • Analysis ID: {analysis.get('image_id', 'N/A')}\")\n",
    "            \n",
    "            if abnormalities:\n",
    "                print(f\"\\n🔍 Detected Abnormalities:\")\n",
    "                for i, abnormality in enumerate(abnormalities, 1):\n",
    "                    conf = abnormality.get('confidence', 0)\n",
    "                    print(f\"   {i}. {abnormality.get('type', 'Unknown').title()}\")\n",
    "                    print(f\"      Location: {abnormality.get('location', 'Not specified')}\")\n",
    "                    print(f\"      Confidence: {conf:.0%}\")\n",
    "            \n",
    "            print(f\"\\n📋 Overall Assessment: {analysis.get('overall_assessment', 'Complete')}\")\n",
    "            print(f\"\\n⚠️  Please have this report reviewed by a qualified medical professional.\")\n",
    "            print(f\"    This AI analysis is for demonstration purposes only.\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Analysis failed: {results['error']}\")\n",
    "\n",
    "print(\"✅ Main MRI Analysis System class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cf560",
   "metadata": {},
   "source": [
    "## 9. Image Upload Interface\n",
    "\n",
    "Create interactive file upload widgets with drag-and-drop functionality for MRI scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIUploadInterface:\n",
    "    \"\"\"Interactive interface for MRI upload and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_system: MRIAnalysisSystem):\n",
    "        self.analysis_system = analysis_system\n",
    "        self.uploaded_files = {}\n",
    "        self.results = None\n",
    "        \n",
    "        # Create widgets\n",
    "        self.file_upload = widgets.FileUpload(\n",
    "            accept='.jpg,.jpeg,.png,.dicom,.dcm',\n",
    "            multiple=False,\n",
    "            description='Upload MRI'\n",
    "        )\n",
    "        self.patient_id_input = widgets.Text(\n",
    "            value='Anonymous',\n",
    "            placeholder='Enter Patient ID',\n",
    "            description='Patient ID:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.analyze_button = widgets.Button(\n",
    "            description='Analyze MRI',\n",
    "            disabled=True,\n",
    "            button_style='primary',\n",
    "            tooltip='Click to analyze the uploaded MRI',\n",
    "            icon='search'\n",
    "        )\n",
    "        self.view_report_button = widgets.Button(\n",
    "            description='View Full Report',\n",
    "            disabled=True,\n",
    "            button_style='info',\n",
    "            tooltip='Click to view the full HTML report',\n",
    "            icon='file-text'\n",
    "        )\n",
    "        self.progress_bar = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info',\n",
    "            orientation='horizontal'\n",
    "        )\n",
    "        self.status_label = widgets.HTML(value=\"<p>Please upload an MRI scan to begin.</p>\")\n",
    "        self.output_area = widgets.Output()\n",
    "        \n",
    "        # Register callbacks\n",
    "        self.file_upload.observe(self._on_file_upload, names='value')\n",
    "        self.analyze_button.on_click(self._on_analyze_click)\n",
    "        self.view_report_button.on_click(self._on_view_report_click)\n",
    "\n",
    "    def _on_file_upload(self, change):\n",
    "        \"\"\"Handle file upload event\"\"\"\n",
    "        self.status_label.value = \"<p style='color: #007bff;'>Processing upload...</p>\"\n",
    "        with self.output_area:\n",
    "            clear_output()\n",
    "            \n",
    "        try:\n",
    "            # The 'new' value from the FileUpload widget\n",
    "            uploaded_value = change['new']\n",
    "            \n",
    "            if not uploaded_value:\n",
    "                self.uploaded_files = {}\n",
    "                self.analyze_button.disabled = True\n",
    "                self.status_label.value = \"<p>Upload cancelled. Please upload an MRI scan.</p>\"\n",
    "                return\n",
    "\n",
    "            # Handle new tuple-based format from ipywidgets\n",
    "            if isinstance(uploaded_value, tuple):\n",
    "                if not uploaded_value:\n",
    "                     raise ValueError(\"File upload value is an empty tuple.\")\n",
    "                file_info = uploaded_value[0] # Get the first file info object\n",
    "                filename = file_info.name\n",
    "                file_content = file_info.content\n",
    "            # Handle old dict-based format for backward compatibility\n",
    "            elif isinstance(uploaded_value, dict):\n",
    "                filename = list(uploaded_value.keys())[0]\n",
    "                file_content = uploaded_value[filename]['content']\n",
    "            else:\n",
    "                raise TypeError(f\"Unexpected type for uploaded file value: {type(uploaded_value)}\")\n",
    "\n",
    "            # Store file data\n",
    "            self.uploaded_files = {filename: file_content}\n",
    "            \n",
    "            # Validate image\n",
    "            MRIImageHandler.validate_image(image_data=file_content)\n",
    "            \n",
    "            # Update UI\n",
    "            self.analyze_button.disabled = False\n",
    "            self.status_label.value = f\"<p style='color: #28a745;'>✅ Ready to analyze: <strong>{filename}</strong></p>\"\n",
    "            \n",
    "            # Display thumbnail\n",
    "            with self.output_area:\n",
    "                print(\"🖼️ Uploaded Image Preview:\")\n",
    "                MRIImageHandler.display_image(image_data=file_content, title=filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"❌ Upload error: {str(e)}\"\n",
    "            self.status_label.value = f\"<p style='color: #dc3545;'>{error_msg}</p>\"\n",
    "            with self.output_area:\n",
    "                print(error_msg)\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            self.analyze_button.disabled = True\n",
    "\n",
    "    def _on_analyze_click(self, button):\n",
    "        \"\"\"Handle analyze button click\"\"\"\n",
    "        # Check if files are uploaded\n",
    "        if not self.uploaded_files:\n",
    "            self.status_label.value = \"<p style='color: #dc3545;'>❌ Please upload a file first</p>\"\n",
    "            return\n",
    "        \n",
    "        # Disable button during analysis\n",
    "        self.analyze_button.disabled = True\n",
    "        self.view_report_button.disabled = True\n",
    "        \n",
    "        # Clear previous output\n",
    "        with self.output_area:\n",
    "            clear_output()\n",
    "        \n",
    "        # Start progress\n",
    "        self.progress_bar.value = 10\n",
    "        self.status_label.value = \"<p style='color: #007bff;'>🔄 Starting analysis...</p>\"\n",
    "        \n",
    "        try:\n",
    "            # Get the uploaded file\n",
    "            filename = list(self.uploaded_files.keys())[0]\n",
    "            file_data = self.uploaded_files[filename]\n",
    "            \n",
    "            # Validate file data\n",
    "            if not file_data or len(file_data) == 0:\n",
    "                raise ValueError(\"File appears to be empty\")\n",
    "            \n",
    "            self.progress_bar.value = 30\n",
    "            self.status_label.value = \"<p style='color: #007bff;'>🧠 AI analyzing image...</p>\"\n",
    "            \n",
    "            # Run analysis\n",
    "            patient_id = self.patient_id_input.value or 'Anonymous'\n",
    "            results = self.analysis_system.analyze_mri_image(\n",
    "                image_data=file_data,\n",
    "                patient_id=patient_id,\n",
    "                filename=filename\n",
    "            )\n",
    "            \n",
    "            self.progress_bar.value = 90\n",
    "            \n",
    "            # Store results\n",
    "            self.results = results\n",
    "            \n",
    "            # Display results in output area\n",
    "            with self.output_area:\n",
    "                if results['success']:\n",
    "                    self.analysis_system.display_results_summary(results)\n",
    "                else:\n",
    "                    print(f\"❌ Analysis failed: {results['error']}\")\n",
    "            \n",
    "            self.progress_bar.value = 100\n",
    "            \n",
    "            if results['success']:\n",
    "                self.status_label.value = \"<p style='color: #28a745;'>✅ Analysis complete! Report generated.</p>\"\n",
    "                self.view_report_button.disabled = False\n",
    "            else:\n",
    "                self.status_label.value = f\"<p style='color: #dc3545;'>❌ Analysis failed: {results.get('error', 'Unknown error')}</p>\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            with self.output_area:\n",
    "                print(f\"❌ Error during analysis: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            self.status_label.value = f\"<p style='color: #dc3545;'>❌ Error: {str(e)}</p>\"\n",
    "            self.progress_bar.value = 0\n",
    "        \n",
    "        finally:\n",
    "            # Re-enable button\n",
    "            self.analyze_button.disabled = False\n",
    "\n",
    "    def _on_view_report_click(self, button):\n",
    "        \"\"\"Handle view report button click\"\"\"\n",
    "        with self.output_area:\n",
    "            clear_output()\n",
    "            if self.results and self.results['success']:\n",
    "                print(\"📄 Displaying Full HTML Report...\")\n",
    "                display(HTML(self.results['html_report']))\n",
    "            else:\n",
    "                print(\"❌ No report available to display.\")\n",
    "    \n",
    "    def create_upload_widget(self):\n",
    "        \"\"\"Create and return the full widget layout\"\"\"\n",
    "        \n",
    "        # Layout\n",
    "        controls = widgets.VBox([\n",
    "            self.patient_id_input,\n",
    "            self.file_upload,\n",
    "            self.status_label,\n",
    "            self.progress_bar,\n",
    "            widgets.HBox([self.analyze_button, self.view_report_button])\n",
    "        ])\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(\"<h2>🖼️ MRI Anomaly Detection Interface</h2>\"),\n",
    "            controls,\n",
    "            self.output_area\n",
    "        ])\n",
    "\n",
    "print(\"✅ MRI Upload Interface class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1f243",
   "metadata": {},
   "source": [
    "## 10. Analysis Pipeline Execution\n",
    "\n",
    "Initialize the system and create the interactive interface for MRI analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e607a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MRI Analysis System\n",
    "print(\"🚀 Initializing MRI Analysis System...\")\n",
    "\n",
    "# Create the main analysis system\n",
    "mri_system = MRIAnalysisSystem(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "# Create the upload interface\n",
    "upload_interface = MRIUploadInterface(mri_system)\n",
    "\n",
    "# Create and display the interface\n",
    "interface_widget = upload_interface.create_upload_widget()\n",
    "\n",
    "print(\"✅ System initialized successfully!\")\n",
    "print(\"📱 Interactive interface ready below...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interactive MRI upload and analysis interface\n",
    "display(interface_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd832c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10.1. AI Chat Interface\n",
    "\n",
    "print(\"Interactive chat interface for asking medical questions using Tavily AI research and OpenAI GPT-4o-mini responses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46617c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIChatInterface:\n",
    "    \"\"\"Interactive chat interface for medical questions using Tavily AI and OpenAI GPT-4o-mini\"\"\"\n",
    "    \n",
    "    def __init__(self, tavily_api_key: str):\n",
    "        self.tavily_api_key = tavily_api_key\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.7,  # Slightly higher for more conversational responses\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        self.chat_history = []\n",
    "        \n",
    "        # Create widgets\n",
    "        self.question_input = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Ask any medical or MRI-related question...',\n",
    "            description='Question:',\n",
    "            disabled=False,\n",
    "            rows=3,\n",
    "            layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "        \n",
    "        self.ask_button = widgets.Button(\n",
    "            description='Ask AI',\n",
    "            disabled=False,\n",
    "            button_style='success',\n",
    "            tooltip='Get AI-powered answer with research',\n",
    "            icon='question-circle'\n",
    "        )\n",
    "        \n",
    "        self.research_toggle = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Include Tavily Research',\n",
    "            disabled=False,\n",
    "            tooltip='Include web research in the response'\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear Chat',\n",
    "            disabled=False,\n",
    "            button_style='warning',\n",
    "            tooltip='Clear chat history',\n",
    "            icon='trash'\n",
    "        )\n",
    "        \n",
    "        self.chat_output = widgets.Output()\n",
    "        \n",
    "        # Register callbacks\n",
    "        self.ask_button.on_click(self._on_ask_click)\n",
    "        self.clear_button.on_click(self._on_clear_click)\n",
    "        self.question_input.observe(self._on_enter_key, names='value')\n",
    "    \n",
    "    def _on_enter_key(self, change):\n",
    "        \"\"\"Handle Enter key in question input (Ctrl+Enter to submit)\"\"\"\n",
    "        # Note: In Jupyter, we can't easily detect Ctrl+Enter, but users can click the button\n",
    "        pass\n",
    "    \n",
    "    def _search_tavily(self, question: str) -> str:\n",
    "        \"\"\"Search Tavily AI for relevant information\"\"\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"api_key\": self.tavily_api_key,\n",
    "            \"query\": f\"medical health {question}\",\n",
    "            \"search_depth\": \"advanced\",\n",
    "            \"max_results\": 5,\n",
    "            \"include_answer\": True\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.tavily.com/v1/search\",\n",
    "                json=payload,\n",
    "                headers=headers\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                \n",
    "                # Combine answer and top results\n",
    "                research_content = \"\"\n",
    "                \n",
    "                # Include the direct answer if available\n",
    "                if results.get('answer'):\n",
    "                    research_content += f\"Direct Answer: {results['answer']}\\n\\n\"\n",
    "                \n",
    "                # Include top search results\n",
    "                if results.get('results'):\n",
    "                    research_content += \"Additional Research:\\n\"\n",
    "                    for i, result in enumerate(results['results'][:3], 1):\n",
    "                        research_content += f\"{i}. {result.get('title', 'No title')}\\n\"\n",
    "                        research_content += f\"   {result.get('content', 'No content')[:200]}...\\n\\n\"\n",
    "                \n",
    "                return research_content\n",
    "            else:\n",
    "                return f\"Research unavailable (Status: {response.status_code})\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Research error: {str(e)}\"\n",
    "    \n",
    "    def _generate_response(self, question: str, research_data: str = \"\") -> str:\n",
    "        \"\"\"Generate AI response using OpenAI GPT-4o-mini\"\"\"\n",
    "        \n",
    "        # Create context-aware prompt\n",
    "        if research_data:\n",
    "            prompt_text = f\"\"\"You are a knowledgeable medical AI assistant. A user has asked the following question, and I've gathered some research information to help inform your response.\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Research Information:\n",
    "{research_data}\n",
    "\n",
    "Please provide a comprehensive, accurate, and helpful response based on the question and research information. Follow these guidelines:\n",
    "\n",
    "1. Be informative but accessible to general audiences\n",
    "2. Include relevant medical terminology with explanations\n",
    "3. Mention when something requires professional medical consultation\n",
    "4. Be balanced and evidence-based\n",
    "5. Include appropriate medical disclaimers when discussing health conditions\n",
    "6. Format your response clearly with sections if needed\n",
    "\n",
    "Important: Always include a disclaimer that this is for educational purposes only and not a substitute for professional medical advice.\n",
    "\n",
    "Response:\"\"\"\n",
    "        else:\n",
    "            prompt_text = f\"\"\"You are a knowledgeable medical AI assistant. Please answer the following question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Guidelines:\n",
    "1. Provide accurate, evidence-based information\n",
    "2. Be accessible to general audiences while including relevant medical terms\n",
    "3. Always mention when professional medical consultation is needed\n",
    "4. Include appropriate disclaimers about educational vs. medical advice\n",
    "5. Be comprehensive but concise\n",
    "\n",
    "Important: Always include a disclaimer that this is for educational purposes only and not a substitute for professional medical advice.\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Use the LLM to generate response\n",
    "            prompt_template = ChatPromptTemplate.from_template(prompt_text)\n",
    "            chain = prompt_template | self.llm\n",
    "            result = chain.invoke({})\n",
    "            \n",
    "            response = result.content if hasattr(result, 'content') else str(result)\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def _on_ask_click(self, button):\n",
    "        \"\"\"Handle ask button click\"\"\"\n",
    "        question = self.question_input.value.strip()\n",
    "        \n",
    "        if not question:\n",
    "            with self.chat_output:\n",
    "                print(\"❌ Please enter a question first.\")\n",
    "            return\n",
    "        \n",
    "        # Disable button during processing\n",
    "        self.ask_button.disabled = True\n",
    "        self.ask_button.description = 'Processing...'\n",
    "        \n",
    "        with self.chat_output:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"🙋 Question: {question}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Get research if enabled\n",
    "            research_data = \"\"\n",
    "            if self.research_toggle.value:\n",
    "                print(\"🔍 Searching for relevant research...\")\n",
    "                research_data = self._search_tavily(question)\n",
    "                print(\"✅ Research completed.\")\n",
    "            \n",
    "            # Generate AI response\n",
    "            print(\"🤖 Generating AI response...\")\n",
    "            response = self._generate_response(question, research_data)\n",
    "            \n",
    "            print(\"\\n💬 AI Response:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(response)\n",
    "            \n",
    "            # Add to chat history\n",
    "            self.chat_history.append({\n",
    "                'question': question,\n",
    "                'research': research_data if self.research_toggle.value else None,\n",
    "                'response': response,\n",
    "                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n📝 Added to chat history (Total: {len(self.chat_history)} conversations)\")\n",
    "        \n",
    "        # Clear input and re-enable button\n",
    "        self.question_input.value = ''\n",
    "        self.ask_button.disabled = False\n",
    "        self.ask_button.description = 'Ask AI'\n",
    "    \n",
    "    def _on_clear_click(self, button):\n",
    "        \"\"\"Handle clear chat button click\"\"\"\n",
    "        self.chat_history = []\n",
    "        with self.chat_output:\n",
    "            clear_output()\n",
    "            print(\"🧹 Chat history cleared!\")\n",
    "    \n",
    "    def create_chat_widget(self):\n",
    "        \"\"\"Create and return the chat interface widget\"\"\"\n",
    "        \n",
    "        # Controls layout\n",
    "        controls = widgets.VBox([\n",
    "            self.question_input,\n",
    "            widgets.HBox([\n",
    "                self.research_toggle,\n",
    "                self.ask_button,\n",
    "                self.clear_button\n",
    "            ]),\n",
    "        ])\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(\"<h3>🤖 AI Medical Assistant</h3>\"),\n",
    "            widgets.HTML(\"<p><em>Ask questions about medical topics, MRI imaging, health conditions, and more!</em></p>\"),\n",
    "            controls,\n",
    "            self.chat_output\n",
    "        ])\n",
    "    \n",
    "    def export_chat_history(self) -> str:\n",
    "        \"\"\"Export chat history as formatted text\"\"\"\n",
    "        if not self.chat_history:\n",
    "            return \"No chat history to export.\"\n",
    "        \n",
    "        export_text = \"AI Medical Chat History\\n\"\n",
    "        export_text += \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        for i, chat in enumerate(self.chat_history, 1):\n",
    "            export_text += f\"Conversation {i} - {chat['timestamp']}\\n\"\n",
    "            export_text += \"-\" * 30 + \"\\n\"\n",
    "            export_text += f\"Question: {chat['question']}\\n\\n\"\n",
    "            \n",
    "            if chat['research']:\n",
    "                export_text += f\"Research Data:\\n{chat['research']}\\n\\n\"\n",
    "            \n",
    "            export_text += f\"AI Response:\\n{chat['response']}\\n\\n\"\n",
    "            export_text += \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        return export_text\n",
    "\n",
    "print(\"✅ AI Chat Interface class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and display the AI Chat Interface\n",
    "print(\"🤖 Initializing AI Chat Interface...\")\n",
    "\n",
    "# Create the chat interface\n",
    "chat_interface = AIChatInterface(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "# Create and display the chat widget\n",
    "chat_widget = chat_interface.create_chat_widget()\n",
    "\n",
    "print(\"✅ AI Chat Interface ready!\")\n",
    "print(\"💬 Ask any medical or MRI-related questions below:\")\n",
    "\n",
    "# Display the chat interface\n",
    "display(chat_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the AI Chat Interface\n",
    "\n",
    "def save_chat_history(filename: str = None):\n",
    "    \"\"\"Save chat history to a file\"\"\"\n",
    "    if filename is None:\n",
    "        filename = f\"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "    \n",
    "    history_text = chat_interface.export_chat_history()\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(history_text)\n",
    "    \n",
    "    print(f\"💾 Chat history saved to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def get_chat_stats():\n",
    "    \"\"\"Get statistics about the chat sessions\"\"\"\n",
    "    if not chat_interface.chat_history:\n",
    "        print(\"📊 No chat history available.\")\n",
    "        return\n",
    "    \n",
    "    total_conversations = len(chat_interface.chat_history)\n",
    "    conversations_with_research = sum(1 for chat in chat_interface.chat_history if chat['research'])\n",
    "    \n",
    "    print(\"📊 Chat Statistics:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Total Conversations: {total_conversations}\")\n",
    "    print(f\"With Research: {conversations_with_research}\")\n",
    "    print(f\"Without Research: {total_conversations - conversations_with_research}\")\n",
    "    \n",
    "    if chat_interface.chat_history:\n",
    "        first_chat = chat_interface.chat_history[0]['timestamp']\n",
    "        last_chat = chat_interface.chat_history[-1]['timestamp']\n",
    "        print(f\"First Question: {first_chat}\")\n",
    "        print(f\"Latest Question: {last_chat}\")\n",
    "\n",
    "def ask_quick_question(question: str, include_research: bool = True):\n",
    "    \"\"\"Quick function to ask a question programmatically\"\"\"\n",
    "    print(f\"🤖 Quick Question: {question}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get research if requested\n",
    "    research_data = \"\"\n",
    "    if include_research:\n",
    "        print(\"🔍 Searching for research...\")\n",
    "        research_data = chat_interface._search_tavily(question)\n",
    "    \n",
    "    # Generate response\n",
    "    print(\"💭 Generating response...\")\n",
    "    response = chat_interface._generate_response(question, research_data)\n",
    "    \n",
    "    print(\"\\n💬 Response:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(response)\n",
    "    \n",
    "    # Add to history\n",
    "    chat_interface.chat_history.append({\n",
    "        'question': question,\n",
    "        'research': research_data if include_research else None,\n",
    "        'response': response,\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    })\n",
    "\n",
    "# Example questions you can try:\n",
    "example_questions = [\n",
    "    \"What are the common types of brain lesions visible on MRI?\",\n",
    "    \"How does contrast enhancement work in MRI imaging?\",\n",
    "    \"What is the difference between T1 and T2 weighted MRI images?\",\n",
    "    \"What are the early signs of multiple sclerosis on MRI?\",\n",
    "    \"How accurate is AI in detecting brain tumors on MRI scans?\",\n",
    "    \"What should patients know before getting an MRI scan?\",\n",
    "    \"What are the limitations of MRI in diagnosing neurological conditions?\"\n",
    "]\n",
    "\n",
    "print(\"✅ Chat utility functions created!\")\n",
    "print(f\"\\n💡 Example questions to try:\")\n",
    "for i, q in enumerate(example_questions, 1):\n",
    "    print(f\"   {i}. {q}\")\n",
    "\n",
    "print(f\"\\n🔧 Available functions:\")\n",
    "print(\"   • save_chat_history() - Save conversation history to file\")\n",
    "print(\"   • get_chat_stats() - View chat statistics\")\n",
    "print(\"   • ask_quick_question('your question') - Ask questions programmatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9abf8",
   "metadata": {},
   "source": [
    "## 11. Batch Processing Implementation\n",
    "\n",
    "Process multiple MRI images simultaneously with progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage function\n",
    "def run_batch_example():\n",
    "    \"\"\"Example of how to run batch processing\"\"\"\n",
    "    # Example with sample file paths (update these with your actual image paths)\n",
    "    sample_images = [\n",
    "        \"sample_mri_1.jpg\",\n",
    "        \"sample_mri_2.jpg\", \n",
    "        \"sample_mri_3.jpg\"\n",
    "    ]\n",
    "    \n",
    "    # Filter to only existing files\n",
    "    existing_images = [img for img in sample_images if os.path.exists(img)]\n",
    "    \n",
    "    if existing_images:\n",
    "        print(f\"Found {len(existing_images)} existing images for batch processing...\")\n",
    "        batch_results = batch_process_mri_images(existing_images, mri_system)\n",
    "        return batch_results\n",
    "    else:\n",
    "        print(\"⚠️  No sample images found. Create some test images first or update the file paths.\")\n",
    "        return []\n",
    "\n",
    "print(\"✅ Batch processing functions created!\")\n",
    "print(\"💡 Use run_batch_example() to test batch processing with sample images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89ac14",
   "metadata": {},
   "source": [
    "## 12. Error Handling and Logging\n",
    "\n",
    "Comprehensive error handling and logging systems for robust operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_analyze_mri(image_path: str, system: MRIAnalysisSystem, \n",
    "                    patient_id: str = \"Anonymous\") -> Dict:\n",
    "    \"\"\"Analyze MRI with comprehensive error handling\"\"\"\n",
    "    logger = logging.getLogger('SafeMRIAnalysis')\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Starting safe analysis for: {image_path}\")\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not image_path or not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        results = system.analyze_mri_image(image_path, patient_id=patient_id)\n",
    "        \n",
    "        if results['success']:\n",
    "            logger.info(f\"Analysis completed successfully. Report: {results['report_path']}\")\n",
    "        else:\n",
    "            logger.error(f\"Analysis failed: {results['error']}\")\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        error_msg = f\"File error: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return {\"success\": False, \"error\": error_msg, \"error_type\": \"file_not_found\"}\n",
    "        \n",
    "    except ValueError as e:\n",
    "        error_msg = f\"Validation error: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return {\"success\": False, \"error\": error_msg, \"error_type\": \"validation_error\"}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error: {str(e)}\"\n",
    "        logger.exception(error_msg)\n",
    "        return {\"success\": False, \"error\": error_msg, \"error_type\": \"unexpected_error\"}\n",
    "\n",
    "def view_system_logs(num_lines: int = 20):\n",
    "    \"\"\"View recent system logs\"\"\"\n",
    "    log_file = 'mri_analysis.log'\n",
    "    \n",
    "    if os.path.exists(log_file):\n",
    "        print(f\"📋 Last {num_lines} log entries:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-num_lines:]:\n",
    "                print(line.strip())\n",
    "    else:\n",
    "        print(\"📝 No log file found yet. Run an analysis first.\")\n",
    "\n",
    "def system_health_check(system: MRIAnalysisSystem) -> Dict:\n",
    "    \"\"\"Perform a system health check\"\"\"\n",
    "    print(\"🏥 Performing System Health Check...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    health_status = {\n",
    "        \"overall_status\": \"healthy\",\n",
    "        \"checks\": {},\n",
    "        \"warnings\": [],\n",
    "        \"errors\": []\n",
    "    }\n",
    "    \n",
    "    # Check API keys\n",
    "    print(\"🔐 Checking API keys...\")\n",
    "    if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        health_status[\"checks\"][\"openai_key\"] = \"✅ Present\"\n",
    "    else:\n",
    "        health_status[\"checks\"][\"openai_key\"] = \"❌ Missing\"\n",
    "        health_status[\"errors\"].append(\"OpenAI API key not configured\")\n",
    "    \n",
    "    if system.tavily_analyzer.api_key:\n",
    "        health_status[\"checks\"][\"tavily_key\"] = \"✅ Present\"\n",
    "    else:\n",
    "        health_status[\"checks\"][\"tavily_key\"] = \"❌ Missing\"\n",
    "        health_status[\"errors\"].append(\"Tavily API key not configured\")\n",
    "    \n",
    "    # Check system components\n",
    "    print(\"🔧 Checking system components...\")\n",
    "    try:\n",
    "        system.explanation_generator.llm\n",
    "        health_status[\"checks\"][\"llm_connection\"] = \"✅ Ready\"\n",
    "    except Exception as e:\n",
    "        health_status[\"checks\"][\"llm_connection\"] = \"❌ Error\"\n",
    "        health_status[\"errors\"].append(f\"LLM connection error: {str(e)}\")\n",
    "    \n",
    "    # Check file permissions\n",
    "    print(\"📁 Checking file permissions...\")\n",
    "    try:\n",
    "        test_file = \"test_write_permission.tmp\"\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        health_status[\"checks\"][\"file_permissions\"] = \"✅ Write access OK\"\n",
    "    except Exception as e:\n",
    "        health_status[\"checks\"][\"file_permissions\"] = \"❌ No write access\"\n",
    "        health_status[\"errors\"].append(f\"File permission error: {str(e)}\")\n",
    "    \n",
    "    # Determine overall status\n",
    "    if health_status[\"errors\"]:\n",
    "        health_status[\"overall_status\"] = \"error\"\n",
    "    elif health_status[\"warnings\"]:\n",
    "        health_status[\"overall_status\"] = \"warning\"\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n🎯 Overall Status: {health_status['overall_status'].upper()}\")\n",
    "    print(\"\\n📊 Component Status:\")\n",
    "    for check, status in health_status[\"checks\"].items():\n",
    "        print(f\"   • {check}: {status}\")\n",
    "    \n",
    "    if health_status[\"warnings\"]:\n",
    "        print(f\"\\n⚠️  Warnings ({len(health_status['warnings'])}):\")\n",
    "        for warning in health_status[\"warnings\"]:\n",
    "            print(f\"   • {warning}\")\n",
    "    \n",
    "    if health_status[\"errors\"]:\n",
    "        print(f\"\\n❌ Errors ({len(health_status['errors'])}):\")\n",
    "        for error in health_status[\"errors\"]:\n",
    "            print(f\"   • {error}\")\n",
    "    \n",
    "    return health_status\n",
    "\n",
    "print(\"✅ Error handling and logging functions created!\")\n",
    "print(\"💡 Use system_health_check(mri_system) to check system status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d40be9",
   "metadata": {},
   "source": [
    "## 13. System Testing Functions\n",
    "\n",
    "Test functions with sample data generation and system validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_mri_images(num_images: int = 3) -> List[str]:\n",
    "    \"\"\"Create sample MRI-like images for testing\"\"\"\n",
    "    print(f\"🖼️  Creating {num_images} sample MRI images for testing...\")\n",
    "    \n",
    "    image_paths = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create a realistic-looking MRI simulation\n",
    "        # Brain-like circular structure with noise\n",
    "        size = 512\n",
    "        image = np.zeros((size, size), dtype=np.uint8)\n",
    "        \n",
    "        # Create brain outline\n",
    "        center = size // 2\n",
    "        brain_radius = size // 3\n",
    "        y, x = np.ogrid[:size, :size]\n",
    "        brain_mask = (x - center)**2 + (y - center)**2 <= brain_radius**2\n",
    "        \n",
    "        # Add brain tissue with varying intensities\n",
    "        brain_tissue = np.random.normal(120, 30, (size, size))\n",
    "        brain_tissue = np.clip(brain_tissue, 0, 255).astype(np.uint8)\n",
    "        image[brain_mask] = brain_tissue[brain_mask]\n",
    "        \n",
    "        # Add some random \"lesions\" for variety\n",
    "        if i > 0:  # Add lesions to some images\n",
    "            num_lesions = np.random.randint(1, 4)\n",
    "            for _ in range(num_lesions):\n",
    "                lesion_x = np.random.randint(center-brain_radius//2, center+brain_radius//2)\n",
    "                lesion_y = np.random.randint(center-brain_radius//2, center+brain_radius//2)\n",
    "                lesion_size = np.random.randint(5, 15)\n",
    "                \n",
    "                y_lesion, x_lesion = np.ogrid[:size, :size]\n",
    "                lesion_mask = (x_lesion - lesion_x)**2 + (y_lesion - lesion_y)**2 <= lesion_size**2\n",
    "                image[lesion_mask] = 200  # Bright lesion\n",
    "        \n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 10, (size, size))\n",
    "        image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Save image\n",
    "        filename = f\"sample_mri_{i+1}.jpg\"\n",
    "        Image.fromarray(image, mode='L').save(filename)\n",
    "        image_paths.append(filename)\n",
    "        \n",
    "        print(f\"   ✅ Created: {filename}\")\n",
    "    \n",
    "    print(f\"✨ Successfully created {len(image_paths)} sample images!\")\n",
    "    return image_paths\n",
    "\n",
    "def test_system_components():\n",
    "    \"\"\"Test individual system components\"\"\"\n",
    "    print(\"🧪 Testing System Components...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_results = {\n",
    "        \"image_handler\": False,\n",
    "        \"tavily_analyzer\": False,\n",
    "        \"explanation_generator\": False,\n",
    "        \"report_generator\": False,\n",
    "        \"main_system\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Test Image Handler\n",
    "        print(\"1️⃣  Testing Image Handler...\")\n",
    "        handler = MRIImageHandler()\n",
    "        # Create a tiny test image\n",
    "        test_img = np.random.randint(0, 255, (100, 100), dtype=np.uint8)\n",
    "        test_path = \"test_component.jpg\"\n",
    "        Image.fromarray(test_img).save(test_path)\n",
    "        \n",
    "        handler.validate_image(test_path)\n",
    "        encoded = handler.encode_image_base64(test_path)\n",
    "        assert len(encoded) > 0\n",
    "        os.remove(test_path)\n",
    "        test_results[\"image_handler\"] = True\n",
    "        print(\"   ✅ Image Handler: PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Image Handler: FAILED - {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        # Test Tavily Analyzer\n",
    "        print(\"2️⃣  Testing Tavily Analyzer...\")\n",
    "        analyzer = TavilyMRIAnalyzer(TAVILY_API_KEY)\n",
    "        # Test with fake image data\n",
    "        fake_results = analyzer.analyze_mri(image_data=b\"fake_data\")\n",
    "        assert \"abnormalities\" in fake_results\n",
    "        test_results[\"tavily_analyzer\"] = True\n",
    "        print(\"   ✅ Tavily Analyzer: PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Tavily Analyzer: FAILED - {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        # Test Explanation Generator\n",
    "        print(\"3️⃣  Testing Explanation Generator...\")\n",
    "        generator = MedicalExplanationGenerator()\n",
    "        test_abnormalities = [{\n",
    "            \"type\": \"test_lesion\",\n",
    "            \"location\": \"test_location\", \n",
    "            \"confidence\": 0.85\n",
    "        }]\n",
    "        explanation = generator.generate_explanation(test_abnormalities, [])\n",
    "        assert len(explanation) > 0\n",
    "        test_results[\"explanation_generator\"] = True\n",
    "        print(\"   ✅ Explanation Generator: PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Explanation Generator: FAILED - {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        # Test Report Generator\n",
    "        print(\"4️⃣  Testing Report Generator...\")\n",
    "        generator = MRIReportGenerator()\n",
    "        test_data = {\n",
    "            \"abnormalities\": [{\"type\": \"test\", \"location\": \"test\"}],\n",
    "            \"overall_assessment\": \"test\"\n",
    "        }\n",
    "        report = generator.generate_html_report(\"test.jpg\", test_data, \"test explanation\")\n",
    "        assert \"<html>\" in report\n",
    "        test_results[\"report_generator\"] = True\n",
    "        print(\"   ✅ Report Generator: PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Report Generator: FAILED - {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        # Test Main System\n",
    "        print(\"5️⃣  Testing Main System...\")\n",
    "        system = MRIAnalysisSystem(TAVILY_API_KEY)\n",
    "        assert system.image_handler is not None\n",
    "        assert system.tavily_analyzer is not None\n",
    "        test_results[\"main_system\"] = True\n",
    "        print(\"   ✅ Main System: PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Main System: FAILED - {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    passed = sum(test_results.values())\n",
    "    total = len(test_results)\n",
    "    \n",
    "    print(f\"\\n📊 Test Summary: {passed}/{total} components passed\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"🎉 All tests passed! System is ready for use.\")\n",
    "    else:\n",
    "        print(\"⚠️  Some tests failed. Check error messages above.\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "def run_full_system_test():\n",
    "    \"\"\"Run a complete end-to-end system test\"\"\"\n",
    "    print(\"🚀 Running Full System Test...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create sample images\n",
    "        print(\"📸 Step 1: Creating sample images...\")\n",
    "        sample_images = create_sample_mri_images(2)\n",
    "        \n",
    "        # Step 2: Test system health\n",
    "        print(\"\\n🏥 Step 2: System health check...\")\n",
    "        health = system_health_check(mri_system)\n",
    "        \n",
    "        if health[\"overall_status\"] == \"error\":\n",
    "            print(\"❌ System health check failed. Fix errors before continuing.\")\n",
    "            return False\n",
    "        \n",
    "        # Step 3: Test individual components\n",
    "        print(\"\\n🧪 Step 3: Component testing...\")\n",
    "        component_results = test_system_components()\n",
    "        \n",
    "        # Step 4: Test with sample image\n",
    "        print(\"\\n🔬 Step 4: End-to-end analysis test...\")\n",
    "        if sample_images:\n",
    "            test_image = sample_images[0]\n",
    "            results = safe_analyze_mri(test_image, mri_system, \"TEST_PATIENT\")\n",
    "            \n",
    "            if results[\"success\"]:\n",
    "                print(\"✅ End-to-end test PASSED!\")\n",
    "                mri_system.display_results_summary(results)\n",
    "            else:\n",
    "                print(f\"❌ End-to-end test FAILED: {results['error']}\")\n",
    "                return False\n",
    "        \n",
    "        # Cleanup\n",
    "        print(\"\\n🧹 Cleaning up test files...\")\n",
    "        for img in sample_images:\n",
    "            if os.path.exists(img):\n",
    "                os.remove(img)\n",
    "                print(f\"   🗑️  Removed: {img}\")\n",
    "        \n",
    "        print(\"\\n🎉 Full system test completed successfully!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Full system test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "print(\"✅ Testing functions created!\")\n",
    "print(\"🧪 Use run_full_system_test() to run comprehensive system tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b8a20",
   "metadata": {},
   "source": [
    "## 14. System Demonstration and Usage\n",
    "\n",
    "### Quick Start Guide\n",
    "\n",
    "1. **📱 Interactive Mode**: Use the upload interface above to analyze MRI images\n",
    "2. **🧪 Test the System**: Run `run_full_system_test()` to verify everything works\n",
    "3. **🔍 Health Check**: Run `system_health_check(mri_system)` to check system status\n",
    "4. **📊 Batch Processing**: Use `batch_process_mri_images()` for multiple images\n",
    "\n",
    "### Usage Examples\n",
    "\n",
    "```python\n",
    "# Test the system\n",
    "run_full_system_test()\n",
    "\n",
    "# Check system health\n",
    "system_health_check(mri_system)\n",
    "\n",
    "# Create sample images for testing\n",
    "sample_images = create_sample_mri_images(3)\n",
    "\n",
    "# Analyze a single image safely\n",
    "results = safe_analyze_mri(\"path/to/your/mri.jpg\", mri_system, \"PATIENT_001\")\n",
    "\n",
    "# View system logs\n",
    "view_system_logs(10)\n",
    "```\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- 🔐 **API Keys**: Your OpenAI and Tavily API keys are configured in this notebook\n",
    "- 📸 **Supported Formats**: JPG, JPEG, PNG, DICOM, DCM files up to 10MB\n",
    "- 🏥 **Medical Disclaimer**: This is for demonstration purposes only - not for actual medical diagnosis\n",
    "- 📄 **Reports**: HTML reports are automatically generated and saved\n",
    "- 🔄 **Logging**: All operations are logged to `mri_analysis.log`\n",
    "\n",
    "### Next Steps for Production Use\n",
    "\n",
    "1. **Replace Simulated Analysis**: Integrate with real medical imaging APIs\n",
    "2. **DICOM Support**: Add proper DICOM file parsing\n",
    "3. **Security**: Implement proper authentication and data encryption\n",
    "4. **HIPAA Compliance**: Add healthcare data protection measures\n",
    "5. **Database Integration**: Store results in medical databases\n",
    "6. **Web Interface**: Create a proper web application using Streamlit/Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789dd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the system\n",
    "run_full_system_test()\n",
    "\n",
    "# Check system health\n",
    "system_health_check(mri_system)\n",
    "\n",
    "# Create sample images for testing\n",
    "sample_images = create_sample_mri_images(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a single image safely\n",
    "results = safe_analyze_mri(\"C:/Users/ahpuh/Desktop/hg/sample_mri_1.jpg\", mri_system, \"PATIENT_001\")\n",
    "\n",
    "# View system logs\n",
    "view_system_logs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76550219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick system demonstration\n",
    "print(\"🎬 MRI Anomaly Detection System - Quick Demo\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Perform system health check\n",
    "print(\"🏥 Checking system health...\")\n",
    "health_status = system_health_check(mri_system)\n",
    "\n",
    "if health_status[\"overall_status\"] != \"error\":\n",
    "    print(\"\\n🧪 Running component tests...\")\n",
    "    test_results = test_system_components()\n",
    "    \n",
    "    print(\"\\n✨ System is ready for use!\")\n",
    "    print(\"\\n📱 Use the interactive interface above to upload and analyze MRI images.\")\n",
    "    print(\"🔬 Or run run_full_system_test() for a complete demonstration.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Please fix system errors before using the MRI analysis system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
